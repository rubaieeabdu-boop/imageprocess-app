import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import random

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="Ù…Ø®ØªØ¨Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)


# Ø¥Ø¶Ø§ÙØ© CSS Ù…Ø®ØµØµ Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµÙ…ÙŠÙ… ÙˆØªØ­Ø³ÙŠÙ† ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
def inject_custom_css():
    st.markdown(
        """
    <style>
    :root{
        --bg1: #0f1724;
        --bg2: #12232e;
        --panel: rgba(255,255,255,0.03);
        --accent: #4db6ac;
        --accent2: #6a5acd;
        --muted: #9aa6b2;
        --card: rgba(255,255,255,0.02);
    }

    /* App background */
    .stApp {
        background: linear-gradient(180deg, var(--bg1) 0%, var(--bg2) 100%) !important;
        color: #e6eef2 !important;
        font-family: 'Inter', system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial !important;
        -webkit-font-smoothing: antialiased !important;
    }

    /* Main container */
    .main .block-container{
        padding: 2rem 2rem 4rem 2rem !important;
        max-width: 1400px !important;
    }

    /* Header */
    .custom-header{
        background: linear-gradient(90deg, rgba(74,70,222,0.98), rgba(77,182,172,0.95)) !important;
        padding: 22px 28px !important;
        border-radius: 14px !important;
        box-shadow: 0 10px 30px rgba(13,18,25,0.6) !important;
        margin-bottom: 1.5rem !important;
    }
    .custom-header h1 { margin:0; font-size:28px; color: #fff !important; }
    .custom-header p { margin:4px 0 0 0; color: rgba(255,255,255,0.9) !important; }

    /* Cards / sections */
    .section {
        background: linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01)) !important;
        border-radius: 12px !important;
        padding: 18px !important;
        margin-bottom: 1rem !important;
        border: 1px solid rgba(255,255,255,0.03) !important;
        box-shadow: 0 6px 20px rgba(2,6,23,0.6) !important;
    }

    /* Buttons */
    .stButton>button {
        background: linear-gradient(90deg, var(--accent), var(--accent2)) !important;
        color: #fff !important;
        border: none !important;
        padding: 10px 18px !important;
        border-radius: 999px !important;
        font-weight: 700 !important;
        box-shadow: 0 6px 18px rgba(57,101,119,0.12) !important;
        transition: transform .12s ease-in-out !important;
    }
    .stButton>button:hover { transform: translateY(-3px) !important; }

    /* Upload box */
    .upload-area {
        border: 2px dashed rgba(255,255,255,0.06) !important;
        background: linear-gradient(180deg, rgba(255,255,255,0.01), rgba(255,255,255,0.00)) !important;
        border-radius: 12px !important;
        padding: 18px !important;
        text-align: center !important;
    }
    .upload-area p { color: var(--muted) !important; margin:0 !important; }

    /* Image boxes */
    .image-card {
        border-radius: 10px !important;
        padding: 8px !important;
        background: var(--card) !important;
        text-align: center !important;
    }

    /* Code editor style */
    .code-editor {
        background: rgba(8,10,12,0.35) !important;
        border-radius: 8px !important;
        padding: 8px !important;
        margin-bottom: 8px !important;
    }

    /* Tabs */
    .stTabs [data-baseweb="tab-list"] {
        background: linear-gradient(90deg, rgba(255,255,255,0.01), rgba(255,255,255,0.00)) !important;
        padding: 8px !important;
        border-radius: 10px !important;
    }
    .stTabs [data-baseweb="tab"] {
        background: rgba(255,255,255,0.02) !important;
        color: #e6eef2 !important;
        border-radius: 9px !important;
        padding: 10px 14px !important;
        font-weight: 700 !important;
    }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(90deg, rgba(255,255,255,0.04), rgba(255,255,255,0.02)) !important;
        box-shadow: inset 0 -4px 18px rgba(0,0,0,0.4) !important;
        color: #fff !important;
    }

    footer {
        text-align: center !important;
        color: rgba(255,255,255,0.6) !important;
        padding-top: 16px !important;
    }

    /* Responsive tweaks */
    @media (max-width: 768px) {
        .custom-header h1 { font-size: 20px !important; }
    }

    </style>
    """,
        unsafe_allow_html=True,
    )


# Ø¯Ø§Ù„Ø© Ù„Ø¹Ø±Ø¶ Ù…Ø­Ø±Ø± Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ (Ù…Ø¸Ù‡Ø± ÙÙ‚Ø·)
def display_code_editor(code, language="python", filename="code.py"):
    st.markdown(
        f"""
    <div class="code-editor">
        <div style="display:flex;align-items:center;gap:10px;margin-bottom:6px;">
            <div style="width:10px;height:10px;border-radius:50%;background:#ff5f56"></div>
            <div style="width:10px;height:10px;border-radius:50%;background:#ffbd2e"></div>
            <div style="width:10px;height:10px;border-radius:50%;background:#27ca3f"></div>
            <div style="margin-left:8px;color:#aebec6;font-family:monospace;">{filename}</div>
        </div>
    </div>
    """,
        unsafe_allow_html=True,
    )
    st.code(code, language=language)


# ==================== Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± (Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¹Ù„ÙŠÙ‡Ø§ Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ø³ØªØ¯Ø¹Ø§Ø¦Ù‡Ø§ Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©) ====================

def adjust_brightness_contrast(image, brightness=0, contrast=100):
    brightness = 0 if brightness is None else brightness
    contrast = 100 if contrast is None else contrast

    contrast = float(contrast + 100) / 100.0
    contrast = contrast ** 2

    adjusted_image = cv2.addWeighted(image, contrast, image, 0, brightness - 100)
    return adjusted_image


def convert_color_space(image, conversion_code):
    return cv2.cvtColor(image, conversion_code)


def apply_threshold(image, threshold_type, threshold_value=127):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    if threshold_type == "THRESH_BINARY":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)
    elif threshold_type == "THRESH_BINARY_INV":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)
    elif threshold_type == "THRESH_TRUNC":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TRUNC)
    elif threshold_type == "THRESH_TOZERO":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TOZERO)
    elif threshold_type == "THRESH_TOZERO_INV":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TOZERO_INV)
    elif threshold_type == "THRESH_OTSU":
        _, result = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    else:
        result = gray
    return cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)


def apply_filter(image, filter_type, kernel_size=3):
    if filter_type == "Blur":
        return cv2.blur(image, (kernel_size, kernel_size))
    elif filter_type == "Gaussian Blur":
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    elif filter_type == "Median Blur":
        return cv2.medianBlur(image, kernel_size)
    elif filter_type == "Sharpen":
        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Emboss":
        kernel = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Edge Detection":
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
    return image


def add_noise(image, noise_type):
    if noise_type == "Gaussian":
        row, col, ch = image.shape
        mean = 0
        var = 0.1
        sigma = var ** 0.5
        gauss = np.random.normal(mean, sigma, (row, col, ch))
        gauss = gauss.reshape(row, col, ch)
        noisy = image + gauss * 50
        return np.clip(noisy, 0, 255).astype(np.uint8)
    elif noise_type == "Salt & Pepper":
        row, col, ch = image.shape
        s_vs_p = 0.5
        amount = 0.04
        noisy = np.copy(image)
        # Salt mode
        num_salt = np.ceil(amount * image.size * s_vs_p)
        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 255
        # Pepper mode
        num_pepper = np.ceil(amount * image.size * (1. - s_vs_p))
        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 0
        return noisy
    return image


def remove_noise(image, filter_type):
    if filter_type == "Median":
        return cv2.medianBlur(image, 5)
    elif filter_type == "Gaussian":
        return cv2.GaussianBlur(image, (5, 5), 0)
    elif filter_type == "Bilateral":
        return cv2.bilateralFilter(image, 9, 75, 75)
    return image


def detect_edges(image, method, threshold1=100, threshold2=200):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    if method == "Canny":
        edges = cv2.Canny(gray, threshold1, threshold2)
    elif method == "Sobel":
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)
        edges = np.sqrt(sobelx ** 2 + sobely ** 2)
        edges = np.uint8(edges / np.max(edges) * 255)
    elif method == "Laplacian":
        edges = cv2.Laplacian(gray, cv2.CV_64F)
        edges = np.uint8(np.absolute(edges))
    else:
        edges = gray
    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)


def apply_morphological_operation(image, operation, kernel_size=3):
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

    if operation == "Erosion":
        result = cv2.erode(binary, kernel, iterations=1)
    elif operation == "Dilation":
        result = cv2.dilate(binary, kernel, iterations=1)
    elif operation == "Opening":
        result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    elif operation == "Closing":
        result = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    else:
        result = binary

    return cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)


def apply_geometric_transform(image, transform, angle=0, scale=1.0):
    h, w = image.shape[:2]

    if transform == "Rotation":
        center = (w // 2, h // 2)
        matrix = cv2.getRotationMatrix2D(center, angle, scale)
        result = cv2.warpAffine(image, matrix, (w, h))
    elif transform == "Scaling":
        result = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)
    elif transform == "Translation":
        matrix = np.float32([[1, 0, 50], [0, 1, 50]])
        result = cv2.warpAffine(image, matrix, (w, h))
    elif transform == "Flipping":
        result = cv2.flip(image, 1)  # 0: vertical, 1: horizontal
    else:
        result = image

    return result


# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª (Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø±ÙˆØ­Ø§Øª) ====================

def lecture_1():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown(
        """
    <p style='font-size: 1.05rem; line-height: 1.8; color: #dbeef7;'>
    Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù‡ÙŠ ØªÙ…Ø«ÙŠÙ„ Ø±Ù‚Ù…ÙŠ Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© ØªØªÙƒÙˆÙ† Ù…Ù† Ù…ØµÙÙˆÙØ© Ù…Ù† Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª. ÙƒÙ„ Ø¨ÙƒØ³Ù„ ÙŠØ­Ù…Ù„ Ù‚ÙŠÙ…Ø© Ø±Ù‚Ù…ÙŠØ© ØªÙ…Ø«Ù„ Ø´Ø¯Ø© Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© ÙˆØ§Ù„Ù„ÙˆÙ† ÙÙŠ ØªÙ„Ùƒ Ø§Ù„Ù†Ù‚Ø·Ø©. 
    ØªØ¹ØªÙ…Ø¯ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø«Ù„Ø§Ø«Ø© Ø¹ÙˆØ§Ù…Ù„ Ø±Ø¦ÙŠØ³ÙŠØ©: Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ø§Ù„Ø·ÙˆÙ„ ÙˆØ§Ù„Ø¹Ø±Ø¶)ØŒ Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù„ÙˆÙ†ÙŠØ©ØŒ ÙˆØ¹Ù…Ù‚ Ø§Ù„Ø¨Øª Ø§Ù„Ø°ÙŠ ÙŠØ­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„ÙƒÙ„ Ø¨ÙƒØ³Ù„.
    </p>
    """,
        unsafe_allow_html=True,
    )

    code = '''
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙ‡Ø§
import cv2
import numpy as np

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
print("Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø©:", image.shape)
print("Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª:", image.shape[2] if len(image.shape) > 2 else 1)
print("Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:", image.dtype)
print("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù„Ø¹Ù„ÙŠØ§:", np.min(image), np.max(image))

# Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
cv2.imwrite('processed_image.jpg', image)
'''
    display_code_editor(code, filename="image_info.py")


def lecture_2():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown(
        """
    <p style='font-size: 1.05rem; line-height: 1.8; color: #dbeef7;'>
    Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø®ØªÙ„ÙØ© ØªØ³ØªØ®Ø¯Ù… Ù„Ø£ØºØ±Ø§Ø¶ Ù…ØªØ¹Ø¯Ø¯Ø© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±. Ù†Ø¸Ø§Ù… RGB Ù‡Ùˆ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„Ø¹Ø±Ø¶ØŒ 
    Ø¨ÙŠÙ†Ù…Ø§ Ù†Ø¸Ø§Ù… HSV Ù…ÙÙŠØ¯ Ù„ÙØµÙ„ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø¹Ù† Ø§Ù„Ù„ÙˆÙ†. Ù†Ø¸Ø§Ù… Grayscale ÙŠØ¨Ø³Ø· Ø§Ù„ØµÙˆØ±Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø¯Ø© ÙÙ‚Ø·.
    </p>
    """,
        unsafe_allow_html=True,
    )

    code = '''
# Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠÙ† Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†
import cv2
import numpy as np

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Grayscale
gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)

# Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ HSV
hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù‚Ù†ÙˆØ§Øª ÙÙŠ Ù†Ø¸Ø§Ù… RGB
red_channel = image_rgb[:, :, 0]
green_channel = image_rgb[:, :, 1]
blue_channel = image_rgb[:, :, 2]
'''
    display_code_editor(code, filename="color_spaces.py")


def lecture_3():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown(
        """
    <p style='font-size: 1.05rem; line-height: 1.8; color: #dbeef7;'>
    ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ† Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±. ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ Ø¨Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø«Ø§Ø¨ØªØ© 
    Ø¥Ù„Ù‰ Ø¬Ù…ÙŠØ¹ ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ø¨ÙƒØ³Ù„ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ø¨ÙŠÙ†Ù…Ø§ ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¨Ø¶Ø±Ø¨ Ù‚ÙŠÙ… Ø§Ù„Ø¨ÙƒØ³Ù„ ÙÙŠ Ù…Ø¹Ø§Ù…Ù„ Ø«Ø§Ø¨Øª. Ù‡Ø°Ù‡ 
    Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ØªØ³Ø§Ø¹Ø¯ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¥Ø¨Ø±Ø§Ø² Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø®ÙÙŠØ©.
    </p>
    """,
        unsafe_allow_html=True,
    )

    code = '''
# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ù„Ø¹ØªØ¨Ø©
import cv2
import numpy as np

def adjust_brightness_contrast(image, brightness=0, contrast=100):
    # Ø¶Ø¨Ø· Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    brightness = 0 if brightness is None else brightness
    contrast = 100 if contrast is None else contrast

    # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
    contrast_factor = float(contrast + 100) / 100.0
    contrast_factor = contrast_factor ** 2

    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©: output = input * contrast + brightness
    adjusted_image = cv2.addWeighted(
        image, contrast_factor, 
        image, 0, 
        brightness - 100
    )

    return adjusted_image
'''
    display_code_editor(code, filename="point_operations.py")


def lecture_4():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown(
        """
    <p style='font-size: 1.05rem; line-height: 1.8; color: #dbeef7;'>
    Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±. ØªØ¹ØªÙ…Ø¯ Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¹Ù„Ù‰ Ù†ÙˆØ§Ø© (Kernel) 
    ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø«Ù„ Ø§Ù„ØªÙ†Ø¹ÙŠÙ…ØŒ Ø§Ù„Ø­Ø¯Ø©ØŒ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø­ÙˆØ§ÙØŒ ÙˆØºÙŠØ±Ù‡Ø§ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª.
    </p>
    """,
        unsafe_allow_html=True,
    )

    code = '''
# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù
import cv2
import numpy as np

def apply_filter(image, filter_type, kernel_size=3):
    # ...
    return image
'''
    display_code_editor(code, filename="filters.py")


def lecture_5():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown(
        """
    <p style='font-size: 1.05rem; line-height: 1.8; color: #dbeef7;'>
    Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ ÙÙŠ Ø§Ù„ØµÙˆØ± Ù‡ÙŠ ØªØ´ÙˆÙ‡Ø§Øª ØºÙŠØ± Ù…Ø±ØºÙˆØ¨ ÙÙŠÙ‡Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙ†ØªØ¬ Ø¹Ù† Ø¸Ø±ÙˆÙ Ø§Ù„ØªØµÙˆÙŠØ± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©. 
    ØªÙˆØ¬Ø¯ Ø£Ù†ÙˆØ§Ø¹ Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ù† Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ù…Ø«Ù„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„ØºÙˆØ³ÙŠØ© ÙˆØ¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ù…Ù„Ø­ ÙˆØ§Ù„ÙÙ„ÙÙ„. 
    ØªÙ‡Ø¯Ù Ø¹Ù…Ù„ÙŠØ§Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©.
    </p>
    """,
        unsafe_allow_html=True,
    )

    code = '''
# Ø¥Ø¶Ø§ÙØ© ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
import cv2
import numpy as np

def add_noise(image, noise_type):
    # ...
    return image
'''
    display_code_editor(code, filename="denoising.py")


def lecture_6():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown(
        """
    <p style='font-size: 1.05rem; line-height: 1.8; color: #dbeef7;'>
    ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ù‡Ùˆ Ø¹Ù…Ù„ÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ØªÙ‡Ø¯Ù Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØªÙŠ ØªØªØºÙŠØ± ÙÙŠÙ‡Ø§ Ø´Ø¯Ø© 
    Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø´ÙƒÙ„ Ù…ÙØ§Ø¬Ø¦. Ù‡Ø°Ù‡ Ø§Ù„Ø­ÙˆØ§Ù ØªÙ…Ø«Ù„ Ø¹Ø§Ø¯Ø© Ø­Ø¯ÙˆØ¯Ù‹Ø§ Ø¨ÙŠÙ† Ù…Ù†Ø§Ø·Ù‚ Ù…Ø®ØªÙ„ÙØ© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© ÙˆÙŠÙ…ÙƒÙ† 
    Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…Ø«Ù„ Ø§Ù„ØªØ¬Ø²Ø¦Ø© ÙˆØ§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡.
    </p>
    """,
        unsafe_allow_html=True,
    )

    code = '''
# ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù ÙÙŠ Ø§Ù„ØµÙˆØ±
import cv2
import numpy as np

def detect_edges(image, method, threshold1=100, threshold2=200):
    # ...
    return image
'''
    display_code_editor(code, filename="edge_detection.py")


def lecture_7():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown(
        """
    <p style='font-size: 1.05rem; line-height: 1.8; color: #dbeef7;'>
    Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© Ù‡ÙŠ ØªÙ‚Ù†ÙŠØ§Øª Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø´ÙƒÙ„ ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©. 
    Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙÙŠØ¯Ø© ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©ØŒ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ØŒ ÙˆØ¹Ø²Ù„ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù„Ø§Ù…Ø­.
    </p>
    """,
        unsafe_allow_html=True,
    )

    code = '''
# Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©
import cv2
import numpy as np

def apply_morphological_operation(image, operation, kernel_size=3):
    # ...
    return image
'''
    display_code_editor(code, filename="morphological.py")


def lecture_8():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown(
        """
    <p style='font-size: 1.05rem; line-height: 1.8; color: #dbeef7;'>
    Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© Ù‡ÙŠ Ø¹Ù…Ù„ÙŠØ§Øª ØªØºÙŠØ± Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ© Ù„Ù„ØµÙˆØ±Ø©. ØªØ´Ù…Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªØ¯ÙˆÙŠØ±ØŒ Ø§Ù„Ù‚ÙŠØ§Ø³ØŒ 
    Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³ØŒ Ø§Ù„Ù‚ØµØŒ ÙˆØ§Ù„Ø§Ù†Ø²ÙŠØ§Ø­. Ù‡Ø°Ù‡ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…ÙÙŠØ¯Ø© ÙÙŠ ØªØµØ­ÙŠØ­ Ø§Ù„ØªØ´ÙˆÙ‡Ø§ØªØŒ ÙˆÙ…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØµÙˆØ±ØŒ ÙˆØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©.
    </p>
    """,
        unsafe_allow_html=True,
    )

    code = '''
# Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© - Ø£Ù…Ø«Ù„Ø©
import cv2
import numpy as np

# Rotation, Scaling, Translation, Flipping, Cropping
'''
    display_code_editor(code, filename="geometric_transforms.py")


# ==================== Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© ====================

def main():
    # Ø­Ù‚Ù† CSS Ø§Ù„Ù…Ø®ØµØµ
    inject_custom_css()

    # Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© / presets
    with st.sidebar:
        st.markdown("<div style='padding:12px 6px;'><h3 style='margin:0;color:#fff;'>ğŸ›ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø³Ø±ÙŠØ¹Ø©</h3></div>", unsafe_allow_html=True)
        st.markdown("---")
        sample_mode = st.radio("Ù†Ù…Ø· Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„ØµÙˆØ±Ø©:", ("Fit", "Fill"), index=0, help="Fit ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªÙ†Ø§Ø³Ø¨ Ø§Ù„ØµÙˆØ±Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ø§ÙˆÙŠØ©ØŒ Fill ÙŠÙ…Ù„Ø£ Ø§Ù„Ø­Ø§ÙˆÙŠØ©.")
        st.markdown("---")
        st.markdown("### ğŸ¯ Ø§Ø®ØªØµØ§Ø±Ø§Øª Ø³Ø±ÙŠØ¹Ø©")
        if st.button("Ø§Ø®ØªÙŠØ§Ø± ØµÙˆØ±Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©", key="rnd_sample"):
            # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ø¨Ø³ÙŠØ·Ø© ÙƒØ§Ù„Ù€ placeholder
            h, w = 512, 512
            rand_img = np.zeros((h, w, 3), dtype=np.uint8)
            rand_img[:] = np.random.randint(40, 200, size=(3,))
            buf = io.BytesIO()
            Image.fromarray(rand_img).save(buf, format="PNG")
            st.session_state["__uploaded_image_bytes__"] = buf.getvalue()
            st.success("ØªÙ… ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© ÙƒÙ†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù…Ø¹Ø§ÙŠÙ†Ø©.")
        st.markdown("---")
        st.markdown("### â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª")
        st.write("ÙˆØ§Ø¬Ù‡Ø© Ù…ÙØ­Ø³Ù‘Ù†Ø© Ù„Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.\nØ¬Ø±Ø¨ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§ØªØŒ Ø§Ù„Ù…Ø±Ø´Ø­Ø§ØªØŒ ÙˆØ§Ù„Ù€ pipeline Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ.")
        st.markdown("---")
        st.caption("ØªÙ… Ø§Ù„ØªØµÙ…ÙŠÙ… ÙˆØ§Ù„ØªØ·ÙˆÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ø¹Ø¨Ø¯Ø§Ù„Ù…Ø¬ÙŠØ¯ Ø±Ø¶ÙˆØ§Ù† Ø§Ù„Ø±Ø¨Ø§Ø¹ÙŠ â€” 2025")

    # Ø§Ù„Ø±Ø£Ø³ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    st.markdown(
        """
    <div class="custom-header">
        <h1>ğŸ¨ Ù…Ø®ØªØ¨Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…</h1>
        <p>Ù…Ø´Ø±ÙˆØ¹ Ù…Ø­Ø§Ø¶Ø±Ø§Øª ÙˆÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ø¹Ù…Ù„ÙŠØ© â€” ØªØµÙ…ÙŠÙ… ÙˆØ§Ø¬Ù‡Ø© Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© ÙˆÙ…Ø¸Ù‡Ø± Ø¹ØµØ±ÙŠ</p>
    </div>
    """,
        unsafe_allow_html=True,
    )

    # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª (Ø¹Ù†Ø§ÙˆÙŠÙ† Ø£Ù‚ØµØ± Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ù„ØªØµÙ…ÙŠÙ…)
    lectures = [
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 1 â€” Ù…Ø¯Ø®Ù„",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 2 â€” Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 3 â€” Ø³Ø·ÙˆØ¹/ØªØ¨Ø§ÙŠÙ†",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 4 â€” Ù…Ø±Ø´Ø­Ø§Øª",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 5 â€” Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 6 â€” ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 7 â€” Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ§",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 8 â€” ØªØ­ÙˆÙŠÙ„Ø§Øª Ù‡Ù†Ø¯Ø³ÙŠØ©",
        "Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"
    ]

    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs(lectures)

    # ÙˆØ¸ÙŠÙØ© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† uploader Ø£Ùˆ Ù…Ù† Ø²Ø± Ø§Ù„Ø¹ÙŠÙ†Ø©
    def load_image_from_uploader(uploader_key, fallback_state_key="__uploaded_image_bytes__"):
        uploaded_file = st.session_state.get(uploader_key, None)
        # First check session state bytes (when sample chosen)
        if fallback_state_key in st.session_state and st.session_state[fallback_state_key] is not None:
            try:
                file_bytes = np.asarray(bytearray(st.session_state[fallback_state_key]), dtype=np.uint8)
                image = cv2.imdecode(file_bytes, 1)
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                return image
            except Exception:
                pass

        # Otherwise check file_uploader object
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ø£Ùˆ Ø§Ø³Ø­Ø¨Ù‡Ø§ Ù‡Ù†Ø§", type=["jpg", "jpeg", "png"], key=uploader_key)
        if uploaded_file is not None:
            try:
                file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
                image = cv2.imdecode(file_bytes, 1)
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                return image
            except Exception as e:
                st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©: " + str(e))
                return None
        return None

    # ----- Tab 1 -----
    with tab1:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 1: Ù…Ø¯Ø®Ù„ ÙˆÙ…Ø¹Ø§ÙŠØ±Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ©")
        lecture_1()
        st.markdown("<div class='section upload-area'><p>ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ù„Ø§ÙƒØªØ´Ø§Ù Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙ‡Ø§ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© â€” Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø²Ø± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ.</p></div>", unsafe_allow_html=True)

        image = load_image_from_uploader("lecture1")
        if image is not None:
            col1, col2 = st.columns([1, 1])
            with col1:
                st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
            with col2:
                st.info("**Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©:**")
                st.write(f"**Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:** `{image.shape[1]} x {image.shape[0]}`")
                st.write(f"**Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª:** `{image.shape[2]}`")
                st.write(f"**Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** `{image.dtype}`")
                st.write(f"**Ù…Ø¯Ù‰ Ø§Ù„Ù‚ÙŠÙ…:** `{int(np.min(image))}` Ø¥Ù„Ù‰ `{int(np.max(image))}`")

    # ----- Tab 2 -----
    with tab2:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 2: Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† (Color Spaces)")
        lecture_2()
        st.write("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")

        image = load_image_from_uploader("lecture2")
        if image is not None:
            color_space = st.selectbox("Ø§Ø®ØªØ± Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ù„Ù„ØªØ­ÙˆÙŠÙ„:", ["RGB", "GRAY", "HSV", "LAB", "YUV"])
            # Ø§Ù…Ù†Ø¹ Ø§Ù„Ø®Ø·Ø£ Ø¨ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±
            try:
                if color_space == "GRAY":
                    converted = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                    converted = cv2.cvtColor(converted, cv2.COLOR_GRAY2RGB)
                elif color_space == "HSV":
                    converted = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
                elif color_space == "LAB":
                    converted = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
                elif color_space == "YUV":
                    converted = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)
                else:
                    converted = image
            except Exception as e:
                st.error("Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­ÙˆÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù†: " + str(e))
                converted = image

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("<div class='image-card'>", unsafe_allow_html=True)
                st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„Ø£ØµÙ„ÙŠØ© (RGB)", use_column_width=True)
                st.markdown("</div>", unsafe_allow_html=True)
            with col2:
                st.markdown("<div class='image-card'>", unsafe_allow_html=True)
                st.image(converted, caption=f"ğŸ”„ Ø§Ù„Ù…Ø­ÙˆÙ„Ø© ({color_space})", use_column_width=True)
                st.markdown("</div>", unsafe_allow_html=True)

    # ----- Tab 3 -----
    with tab3:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 3: ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†")
        lecture_3()
        st.write("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")

        image = load_image_from_uploader("lecture3")
        if image is not None:
            col_img, col_ctrl = st.columns([2, 1])
            with col_img:
                st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
            with col_ctrl:
                brightness = st.slider("ğŸ”† Ø§Ù„Ø³Ø·ÙˆØ¹", -100, 100, 0, key="brightness_slider")
                contrast = st.slider("ğŸŒˆ Ø§Ù„ØªØ¨Ø§ÙŠÙ†", 0, 200, 100, key="contrast_slider")
                threshold = st.slider("âš«ï¸ Ø§Ù„Ø¹ØªØ¨Ø© (Ù„Ù„Ù…Ø¹Ø§ÙŠÙ†Ø©)", 0, 255, 127, key="threshold_slider")
                if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª", key="apply_btn"):
                    with st.spinner("Ø¬Ø§Ø±Ù ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª..."):
                        adjusted = adjust_brightness_contrast(image, brightness, contrast)
                        thresholded = apply_threshold(image, "THRESH_BINARY", threshold)
                        negative = 255 - image
                    tab_a, tab_b, tab_c = st.tabs(["Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†", "Ø§Ù„Ø¹ØªØ¨Ø©", "Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©"])
                    with tab_a:
                        st.image(adjusted, caption="ğŸ”„ Ø§Ù„Ø³Ø·ÙˆØ¹ Ùˆ Ø§Ù„ØªØ¨Ø§ÙŠÙ†", use_column_width=True)
                    with tab_b:
                        st.image(thresholded, caption="âš«ï¸ Ø§Ù„Ø¹ØªØ¨Ø©", use_column_width=True)
                    with tab_c:
                        st.image(negative, caption="ğŸŒ— Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©", use_column_width=True)

    # ----- Tab 4 -----
    with tab4:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 4: Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù")
        lecture_4()
        st.write("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")

        image = load_image_from_uploader("lecture4")
        if image is not None:
            filter_type = st.selectbox("Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ù…Ø±Ø´Ø­:", ["Blur", "Gaussian Blur", "Median Blur", "Sharpen", "Emboss", "Edge Detection"])
            kernel_size = st.slider("Ø­Ø¬Ù… Ø§Ù„Ù†ÙˆØ§Ø© (ÙŠÙØ¶Ù„ ÙØ±Ø¯ÙŠ)", 3, 15, 5, 2, key="kernel_size")
            if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­", key="apply_filter_btn"):
                with st.spinner("Ø¬Ø§Ø±Ù ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­..."):
                    filtered = apply_filter(image, filter_type, kernel_size)
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
                with col2:
                    st.image(filtered, caption=f"âœ¨ Ø¨Ø¹Ø¯ {filter_type}", use_column_width=True)

    # ----- Tab 5 -----
    with tab5:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 5: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡")
        lecture_5()
        st.write("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")

        image = load_image_from_uploader("lecture5")
        if image is not None:
            noise_type = st.selectbox("Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡:", ["Gaussian", "Salt & Pepper"])
            denoise_type = st.selectbox("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡:", ["Median", "Gaussian", "Bilateral"])
            if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", key="apply_denoise_btn"):
                with st.spinner("Ø¬Ø§Ø±Ù Ø¥Ø¶Ø§ÙØ© ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡..."):
                    noisy = add_noise(image, noise_type)
                    denoised = remove_noise(noisy, denoise_type)
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
                with col2:
                    st.image(noisy, caption=f"ğŸ”Š Ù…Ø¹ {noise_type} noise", use_column_width=True)
                with col3:
                    st.image(denoised, caption=f"ğŸ”‡ Ø¨Ø¹Ø¯ {denoise_type} filter", use_column_width=True)

    # ----- Tab 6 -----
    with tab6:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 6: ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù")
        lecture_6()
        st.write("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")

        image = load_image_from_uploader("lecture6")
        if image is not None:
            edge_method = st.selectbox("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù:", ["Canny", "Sobel", "Laplacian", "Prewitt"])
            if edge_method == "Canny":
                threshold1 = st.slider("Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø¯Ù†ÙŠØ§", 0, 255, 100, key="threshold1")
                threshold2 = st.slider("Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø¹Ù„ÙŠØ§", 0, 255, 200, key="threshold2")
            else:
                threshold1, threshold2 = 100, 200

            if st.button("ğŸš€ ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù", key="detect_edges_btn"):
                with st.spinner("Ø¬Ø§Ø±Ù ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù..."):
                    # Prewitt handled locally if selected
                    if edge_method == "Prewitt":
                        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                        kernelx = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])
                        kernely = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])
                        prex = cv2.filter2D(gray, -1, kernelx)
                        prey = cv2.filter2D(gray, -1, kernely)
                        edges = np.sqrt(prex.astype(float) ** 2 + prey.astype(float) ** 2)
                        edges = np.uint8(edges / np.max(edges) * 255)
                        edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
                    else:
                        edges = detect_edges(image, edge_method, threshold1, threshold2)

                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
                with col2:
                    st.image(edges, caption=f"ğŸ” Ø§Ù„Ø­ÙˆØ§Ù Ø¨Ù€ {edge_method}", use_column_width=True)

    # ----- Tab 7 -----
    with tab7:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 7: Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©")
        lecture_7()
        st.write("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")

        image = load_image_from_uploader("lecture7")
        if image is not None:
            morph_operation = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©:", ["Erosion", "Dilation", "Opening", "Closing", "Gradient"])
            kernel_size = st.slider("Ø­Ø¬Ù… Ø§Ù„Ù†ÙˆØ§Ø©", 3, 15, 5, 2, key="morph_kernel_size")
            iterations = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª (Ø³ÙŠØªÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†)", 1, 10, 1, key="morph_iterations")
            if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©", key="apply_morph_btn"):
                with st.spinner("Ø¬Ø§Ø±Ù ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©..."):
                    # apply_morphological_operation Ù„Ø§ ØªÙ‚Ø¨Ù„ iterations ÙÙŠ Ø§Ù„ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£ØµÙ„ÙŠØŒ Ù„Ø°Ø§ Ù†Ø·Ø¨Ù‚ Ø§Ù„ØªÙƒØ±Ø§Ø± Ù‡Ù†Ø§ Ø¨Ø£Ù…Ø§Ù†
                    result = image.copy()
                    # Ù†ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© Ø¨Ù„ÙˆÙ† Ø±Ù…Ø§Ø¯ÙŠ Ø«Ù†Ø§Ø¦ÙŠØ© Ø¥Ù† Ù„Ø²Ù…
                    for i in range(iterations):
                        result = apply_morphological_operation(result, morph_operation, kernel_size)
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
                with col2:
                    st.image(result, caption=f"âœ¨ Ø¨Ø¹Ø¯ {morph_operation} x{iterations}", use_column_width=True)

    # ----- Tab 8 -----
    with tab8:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 8: Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©")
        lecture_8()
        st.write("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")

        image = load_image_from_uploader("lecture8")
        if image is not None:
            transform_type = st.selectbox("Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„ØªØ­ÙˆÙŠÙ„:", ["Rotation", "Scaling", "Translation", "Flipping", "Cropping"])
            result = None

            if transform_type == "Rotation":
                angle = st.slider("Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø¯ÙˆØ±Ø§Ù†", -180, 180, 45, key="rotation_angle")
                scale = st.slider("Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙƒØ¨ÙŠØ±", 0.1, 3.0, 1.0, 0.1, key="rotation_scale")
                if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„", key="apply_transform_rotation"):
                    with st.spinner("Ø¬Ø§Ø±Ù ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¯ÙˆÙŠØ±..."):
                        result = apply_geometric_transform(image, "Rotation", angle=angle, scale=scale)

            elif transform_type == "Scaling":
                scale = st.slider("Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø¹Ø§Ù…", 0.1, 3.0, 1.5, 0.1, key="scale_general")
                if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒØ¨ÙŠØ±", key="apply_transform_scaling"):
                    with st.spinner("Ø¬Ø§Ø±Ù ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒØ¨ÙŠØ±..."):
                        result = apply_geometric_transform(image, "Scaling", scale=scale)

            elif transform_type == "Translation":
                tx = st.slider("Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ø£ÙÙ‚ÙŠØ© (px)", -200, 200, 50, key="translation_x")
                ty = st.slider("Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠØ© (px)", -200, 200, 50, key="translation_y")
                if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¥Ø²Ø§Ø­Ø©", key="apply_transform_translation"):
                    with st.spinner("Ø¬Ø§Ø±Ù ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¥Ø²Ø§Ø­Ø©..."):
                        h, w = image.shape[:2]
                        matrix = np.float32([[1, 0, tx], [0, 1, ty]])
                        result = cv2.warpAffine(image, matrix, (w, h))

            elif transform_type == "Flipping":
                flip_choice = st.selectbox("Ø§Ø®ØªØ± Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³:", [("Ø£ÙÙ‚ÙŠ", 1), ("Ø¹Ù…ÙˆØ¯ÙŠ", 0), ("ÙƒÙ„Ø§Ù‡Ù…Ø§", -1)], format_func=lambda x: x[0])
                if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³", key="apply_transform_flipping"):
                    with st.spinner("Ø¬Ø§Ø±Ù ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³..."):
                        result = cv2.flip(image, flip_choice[1])

            elif transform_type == "Cropping":
                max_w = image.shape[1]
                max_h = image.shape[0]
                x = st.slider("Ø§Ù„Ù†Ù‚Ø·Ø© X", 0, max(0, max_w - 50), 50, key="crop_x")
                y = st.slider("Ø§Ù„Ù†Ù‚Ø·Ø© Y", 0, max(0, max_h - 50), 50, key="crop_y")
                width = st.slider("Ø§Ù„Ø¹Ø±Ø¶", 50, max_w - x, min(200, max_w - x), key="crop_width")
                height = st.slider("Ø§Ù„Ø§Ø±ØªÙØ§Ø¹", 50, max_h - y, min(200, max_h - y), key="crop_height")
                if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Øµ", key="apply_transform_cropping"):
                    with st.spinner("Ø¬Ø§Ø±Ù Ø§Ù„Ù‚Øµ..."):
                        result = image[y : y + height, x : x + width]

            if result is not None:
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
                with col2:
                    st.image(result, caption=f"âœ¨ Ø¨Ø¹Ø¯ {transform_type}", use_column_width=True)

    # ----- Tab 9: Final Project Pipeline -----
    with tab9:
        st.markdown("## Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: pipeline Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±")
        st.markdown("### ğŸ§ª Ø£Ù†Ø´Ø¦ pipeline Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ")
        image = load_image_from_uploader("final_project")
        if image is not None:
            st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
            st.markdown("### âš™ï¸ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
            steps = st.multiselect(
                "Ø§Ø®ØªØ± Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:",
                ["ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ", "Ø¶Ø¨Ø· Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†", "ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­", "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù", "Ø¹ØªØ¨Ø©", "Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©"],
                default=["ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ", "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù"]
            )

            processed_image = image.copy()
            process_history = []

            if st.button("â–¶ï¸ ØªØ´ØºÙŠÙ„ Pipeline", key="run_pipeline"):
                with st.spinner("Ø¬Ø§Ø±Ù ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ pipeline..."):
                    for step in steps:
                        if step == "ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ":
                            processed_image = cv2.cvtColor(processed_image, cv2.COLOR_RGB2GRAY)
                            processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2RGB)
                            process_history.append("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ")

                        elif step == "Ø¶Ø¨Ø· Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†":
                            processed_image = adjust_brightness_contrast(processed_image, 20, 120)
                            process_history.append("Ø¶Ø¨Ø· Ø§Ù„Ø³Ø·ÙˆØ¹ (+20) ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ† (+20%)")

                        elif step == "ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­":
                            processed_image = apply_filter(processed_image, "Gaussian Blur", 5)
                            process_history.append("ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­ Gaussian Blur (5x5)")

                        elif step == "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù":
                            processed_image = detect_edges(processed_image, "Canny", 100, 200)
                            process_history.append("ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ø¨Ù€ Canny")

                        elif step == "Ø¹ØªØ¨Ø©":
                            processed_image = apply_threshold(processed_image, "THRESH_BINARY", 127)
                            process_history.append("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© (127)")

                        elif step == "Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©":
                            # Ù†Ø·Ø¨Ù‚ ØªÙƒØ±Ø§Ø± ÙˆØ§Ø­Ø¯ Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†
                            processed_image = apply_morphological_operation(processed_image, "Closing", 3)
                            process_history.append("Ø¹Ù…Ù„ÙŠØ© Closing Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© (3x3)")

                st.markdown("### ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_column_width=True)
                with col2:
                    st.image(processed_image, caption="âœ¨ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©", use_column_width=True)

                st.markdown("### ğŸ“ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
                for i, step in enumerate(process_history, 1):
                    st.write(f"{i}. {step}")

                # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø© Ù„Ù„ØªØ­Ù…ÙŠÙ„
                buf = io.BytesIO()
                processed_pil = Image.fromarray(processed_image)
                processed_pil.save(buf, format="JPEG", quality=95)
                byte_im = buf.getvalue()

                st.download_button(
                    label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©",
                    data=byte_im,
                    file_name="processed_image.jpg",
                    mime="image/jpeg",
                    use_container_width=True
                )

    # Ø§Ù„ØªØ°ÙŠÙŠÙ„
    st.markdown(
        """
    <footer>
        <p>ØªÙ… Ø§Ù„ØªØµÙ…ÙŠÙ… ÙˆØ§Ù„ØªØ·ÙˆÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ø¹Ø¨Ø¯Ø§Ù„Ù…Ø¬ÙŠØ¯ Ø±Ø¶ÙˆØ§Ù† Ø§Ù„Ø±Ø¨Ø§Ø¹ÙŠ</p>
        <p>Ù…Ø´Ø±ÙˆØ¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ© - ÙƒÙ„ÙŠØ© Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Â© 2025</p>
    </footer>
    """,
        unsafe_allow_html=True,
    )


if __name__ == "__main__":
    main()
